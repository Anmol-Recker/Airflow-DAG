[email]
email_backend = airflow.utils.email.send_email_smtp

[smtp]
# If you want airflow to send emails on retries, failure, and you want to use
# the airflow.utils.email.send_email_smtp function, you have to configure an
# smtp server here
smtp_host = smtp.googlemail.com
smtp_starttls = True
smtp_ssl = False
# Uncomment and set the user/pass settings if you want to use SMTP AUTH
smtp_user = anmol.pal@kockpit.in
smtp_password = shelby5103
smtp_port = 587
smtp_mail_from = smtp.gmail.com





create database anmol:
use anmol;

SET hive.support.sql11.reserved.keywords=false;

ADD FILE ${hiveconf:QUERY_DIR}/reducer_q3.py;
set hive.exec.compress.output=false;

create table clients (Date DATE, Name STRING, Sectors STRING, State STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE TBLPROPERTIES("skip.header.line.count"="1");

create table clients1 (Date DATE, Name STRING, Sectors STRING, State STRING) ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' STORED AS TEXTFILE TBLPROPERTIES("skip.header.line.count"="1");

LOAD DATA LOCAL INPATH '/home/hadoopusr/Invoice.csv' INTO TABLE clients;
LOAD DATA LOCAL INPATH '/home/hadoopusr/Invoice.csv' INTO TABLE clients1;

describle clients;






master hdfs 192.10.15.132:8020

change hdfs-site.xml datanode path

<configuration>
        <property>
                <name>yarn.resourcemanager.resource-tracker.address</name>
                <value>192.10.15.132:8025</value>
        </property>
        <property>
                <name>yarn.resourcemanager.scheduler.address</name>
                <value>192.10.15.132:8030</value>
        </property>
        <property>
                <name>yarn.resourcemanager.address</name>
                <value>192.10.15.132:8050</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services</name>
                <value>mapreduce_shuffle</value>
        </property>
        <property>
                <name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name>
                <value>org.apache.hadoop.mapred.ShuffleHandler</value>
        </property>
        <property>
                <name>yarn.nodemanager.disk-health-checker.min-healthy-disks</name>
                <value>0</value>
</configuration>














